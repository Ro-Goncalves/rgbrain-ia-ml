import streamlit as st
from utils import text
from langchain_community.llms import HuggingFaceEndpoint
from langchain_core.prompts.prompt import PromptTemplate
from langchain.chains.llm import LLMChain

st.set_page_config(
    page_title = "Extrair Informa√ß√µes PDF",
    page_icon = "üìà"
)

def _model():
    return 'mistralai/Mixtral-8x7B-Instruct-v0.1'

def _llm():    
    return HuggingFaceEndpoint(
        repo_id=_model(),
        huggingfacehub_api_token='', 
        temperature=0.5,
        model_kwargs={'max_length':512})

def _template():   
    return """
        Voc√™ est√° lendo um documento que possui informa√ß√µes sobre consorcio.
        Seu objetivo √© extrair as de grupo, cota, c√≥digo do bem ojeto atual,
        valor do bem objeto atual, c√≥digo do bem objeto novo, valor do bem objeto
        novo, extraia somente os n√∫mero, utili

        - **Grupo**:
        - **Cota**:
        - **C√≥digo Bem Objeto atual**:
        - **Valor Bem Objeto atual**:
        - **C√≥digo Bem Objeto Novo**:
        - **Valor Bem Objeto Novo**:

        ```{text}```
    """

def _llm_chain():
    prompt = PromptTemplate(template=_template(), input_variables=['text'])
    return LLMChain(prompt=prompt, llm=_llm())

LLM_CHAIN = _llm_chain()

if ('texto_pdf' not in st.session_state):
    st.session_state.texto_pdf = None

st.markdown("""
    # Vamos Ver o que  h√° no seu PDF? ü§î
    ---
            
    Essa demo extra√≠ informa√ß√µes de um PDF
""")

with st.sidebar:
    pdf_docs = st.file_uploader('D√™-Me seu PDF', accept_multiple_files=True)

    if st.button('Processar'):       
        st.session_state.texto_pdf = text.process_files(pdf_docs)

st.markdown(f"""
    ## Cont√©udo do PDF
    ---
            
    {LLM_CHAIN.invoke(st.session_state.texto_pdf)['text']}
""")